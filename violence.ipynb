{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/violence-detection/Real Life Violence Dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_violence = \"/violence-detection/Real Life Violence Dataset\\Violence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_nonviolence = \"/violence-detection/Real Life Violence Dataset/NonViolence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data/Violence',exist_ok=True)\n",
    "for path in tqdm(glob.glob(PATH_violence+'/*')):\n",
    "    fname = os.path.basename(path).split('.')[0]\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count % 5 == 0:\n",
    "            cv2.imwrite(\"./data/Violence/{}-{}.jpg\".format(fname,str(count).zfill(4)),image)     # save frame as JPEG file      \n",
    "        success,image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data/NonViolence',exist_ok=True)\n",
    "for path in tqdm(glob.glob(PATH_nonviolence+'/*')):\n",
    "    fname = os.path.basename(path).split('.')[0]\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count % 5 == 0:\n",
    "            cv2.imwrite(\"./data/NonViolence/{}-{}.jpg\".format(fname,str(count).zfill(4)),image)     # save frame as JPEG file      \n",
    "        success,image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.applications import ResNet50,MobileNetV2,MobileNet,InceptionV3\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"data\",\n",
    "    \"model\": \"model/violence_model.h5\",\n",
    "    \"label-bin\": \"model/lb.pickle\",\n",
    "    \"epochs\": 10,\n",
    "    \"plot\": \"plot.png\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = set([\"Violence\", \"NonViolence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*100)\n",
    "print(\"[INFO] loading images...\")\n",
    "print('-'*100)\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in tqdm(imagePaths[::]):\n",
    "    label = imagePath.split(os.path.sep)[-2] # Violence / NonViolence\n",
    "\n",
    "    if label not in LABELS:\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reduced_data = data[::10]\n",
    "reduced_labels = labels[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(reduced_data)\n",
    "labels = np.array(reduced_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = InceptionV3(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(5, 5))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "print('-'*100)\n",
    "opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "print('-'*100)\n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=32),\n",
    "    steps_per_epoch=len(trainX) // 32,\n",
    "    validation_data=valAug.flow(testX, testY),\n",
    "    validation_steps=len(testX) // 32,\n",
    "    epochs=args[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "print('-'*100)\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] plot the training loss and accuracy...\")\n",
    "print('-'*100)\n",
    "N = args[\"epochs\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing network...\")\n",
    "print('-'*100)\n",
    "model.save(args[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(args[\"label-bin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "\n",
    "    \"model\": \"model/violence_model.h5\",\n",
    "    \"label-bin\": \"model/lb.pickle\",\n",
    "    \"input\": \"video/street-fight.mp4\",\n",
    "    \"output\": \"output/streetfight_64avg.avi\",\n",
    "    \"size\": 64\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading model and label binarizer...\")\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open(args[\"label-bin\"], \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "Q = deque(maxlen=args[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpath = args[\"input\"]\n",
    "if args[\"input\"] == 'camera':\n",
    "\tvpath = 0\n",
    "vs = cv2.VideoCapture(vpath)\n",
    "writer = None\n",
    "(W, H) = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # if the frame dimensions are empty, grab them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "\n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Q.append(preds)\n",
    "\n",
    "    results = np.array(Q).mean(axis=0)\n",
    "    i = 1\n",
    "    label = lb.classes_[i]\n",
    "    \n",
    "\n",
    "    prob = results[i]*100\n",
    "\n",
    "    text_color = (0, 255, 0) # default : green\n",
    "\n",
    "    if prob > 70 :\n",
    "        text_color = (0, 0, 255) # red\n",
    "        \n",
    "    else:\n",
    "        label = 'Normal'\n",
    "\n",
    "    text = \"State : {:8} ({:3.2f}%)\".format(label,prob)\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "    cv2.putText(output, text, (35, 50), FONT,1.25, text_color, 3) \n",
    "\n",
    "    output = cv2.rectangle(output, (35, 80), (35+int(prob)*5,80+20), text_color,-1)\n",
    "\n",
    "    if writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(args[\"output\"], fourcc, 30,(W, H), True)\n",
    "\n",
    "    writer.write(output)\n",
    "\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "writer.release()\n",
    "vs.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
